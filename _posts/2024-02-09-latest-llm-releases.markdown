---
layout: post
title: "Latest LLM Releases in February 2024"
date: 2024-02-09
categories: AI releases
---


### StarCoder
- **Developer:** StarCoder
- **URL:** [StarCoder](https://huggingface.co/StarCoder)
- **Description:** Sets a new standard for open-source coding LLMs, trained on a vast dataset, excelling in coding benchmarks.

### DeepSeek LLM
- **Developer:** Paper
- **URL:** [DeepSeek LLM](https://huggingface.co/paper/deepseek-llm)
- **Description:** Dedicated to scaling LLMs with a long-term perspective, developed a 2 trillion token dataset.

### DocLLM
- **Developer:** Paper
- **URL:** [DocLLM](https://huggingface.co/paper/docllm)
- **Description:** A layout-aware generative LLM for multimodal document understanding.

### BERT
- **Developer:** Google Research
- **URL:** [BERT](https://github.com/google-research/bert)
- **Description:** Revolutionizes NLP with bidirectional training, excelling in tasks from question answering to language inference.

### OPT-175B
- **Developer:** Meta AI Research
- **URL:** [OPT-175B](https://huggingface.co/facebook/opt-175b)
- **Description:** An open-source LLM with 175 billion parameters, offering remarkable capabilities for zero- and few-shot learning.

### XGen-7B
- **Developer:** Salesforce
- **URL:** [XGen-7B](https://huggingface.co/salesforce/xgen-7b)
- **Description:** Excels in processing up to 8,000 tokens, trained on diverse datasets for advanced linguistic and code-generation tasks.

### Falcon-180B
- **Developer:** Technology Innovation Institute
- **URL:** [Falcon-180B](https://huggingface.co/TII/falcon-180b)
- **Description:** A colossal LLM with 180 billion parameters, outmatching many contemporaries in size and power.

### GPT-NeoX-20B
- **Developer:** EleutherAI
- **URL:** [GPT-NeoX-20B](https://huggingface.co/EleutherAI/gpt-neox-20b)
- **Description:** An autoregressive language model with 20 billion parameters designed for advanced content generation and research purposes​​.

### GPT-J-6B
- **Developer:** EleutherAI
- **URL:** [GPT-J-6B](https://huggingface.co/EleutherAI/gpt-j-6B)
- **Description:** Offers a balance between performance and resource consumption, ideal for startups and medium-sized businesses needing human-like text generation​​.

### Falcon 180B
- **Developer:** Technology Innovation Institute
- **URL:** [Falcon 180B](https://falconllm.tii.ae)
- **Description:** Boasts 180 billion parameters, outperforming competitors in NLP tasks and demonstrating the narrowing gap between proprietary and open-source LLMs.

### OPT-175B
- **Developer:** Meta AI Research
- **URL:** [OPT-175B](https://huggingface.co/facebook/opt-175b)
- **Description:** An LLM with 175 billion parameters, offering capabilities comparable to GPT-3 with a lower environmental footprint.

### Eagle 7B
- **Developer:** RWKV
- **URL:** [Eagle 7B](https://wiki.rwkv.com)
- **Description:** Known as RWKV-v5, an "Attention-Free Transformer" trained on 1.1 trillion tokens across 100+ languages.

### Mamba
- **Developer:** State Spaces
- **URL:** [Mamba](https://github.com/state-spaces/mamba)
- **Description:** Introduces an efficient state-space model for sequence modeling, improving performance across various data modalities.

### Yi-34B
- **Developer:** 01-AI
- **URL:** [Yi-34B](https://huggingface.co/01-ai/Yi-34B)
- **Description:** Open-sourced models for diverse applications like chat, demonstrating top performance with a focus on response diversity.

### TinyLlama
- **Developer:** Paper
- **URL:** [TinyLlama](https://huggingface.co/paper/tinyllama)
- **Description:** A small LLM aiming for efficiency and competitive performance against larger models.

### LLaMA 2
- **Developer:** Meta AI
- **URL:** [Meta AI](https://ai.meta.com)
- **Description:** An advanced open-source LLM offering models from 7 billion to 70 billion parameters, excelling in benchmarks and optimized for Azure and Windows platforms.

### Mistral
- **Developer:** Mistral AI
- **URL:** [Mistral](https://github.com/mistral-ai/mistral)
- **Description:** Designed for high efficiency and performance across various applications, available under the Apache 2.0 license.

### Solar
- **Developer:** Upstage
- **URL:** [Solar 10.7B](https://huggingface.co/Upstage/solar-10.7b)
- **Description:** A small LLM with 10.7 billion parameters that outperforms models like Llama 2 and Mistral-7B in essential NLP tasks.

### Bloom
- **Developer:** BigScience
- **URLs:** [Bloom on Hugging Face](https://huggingface.co/bigscience/bloom), [BigScience](https://bigscience.huggingface.co)
- **Description:** An open-source LLM proficient in 46 languages, designed for autoregressive text generation.

### MPT-7B
- **Developer:** MosaicML
- **URL:** [MPT-7B](https://www.mosaicml.com/mpt-7b)
- **Description:** Optimized for efficiency and suitable for a variety of commercial applications.

### Vicuna-13B
- **Developer:** LMSYS
- **URLs:** [ShareGPT](https://sharegpt.com/vicuna-13b), [Hugging Face](https://huggingface.co/LMSYS/vicuna-13b)
- **Description:** A conversational model fine-tuned from the LLaMa 13B model, showing competitive performance in various applications.


This roundup of the latest LLM releases highlights the diverse and innovative approaches developers are taking to advance AI technology, offering a wide range of capabilities and specializations.

